{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27bb30fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Using cached selenium-3.141.0-py2.py3-none-any.whl (904 kB)\n",
      "Requirement already satisfied: urllib3 in /Users/minjikim/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages (from selenium) (1.26.11)\n",
      "Installing collected packages: selenium\n",
      "Successfully installed selenium-3.141.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f431d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72e663f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크롬창(웹드라이버) 열기\n",
    "driver = webdriver.Chrome(\"/Users/minjikim/Downloads/chromedriver 4\")\n",
    "\n",
    "# 구글 지도 접속하기\n",
    "driver.get(\"https://www.google.com/maps/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5c121f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색창에 \"카페\" 입력하기\n",
    "searchbox = driver.find_element_by_css_selector(\"input#searchboxinput\")\n",
    "searchbox.send_keys(\"Rome gelato\")\n",
    "\n",
    "# 검색버튼 누르기\n",
    "searchbutton = driver.find_element_by_css_selector(\"button#searchbox-searchbutton\")\n",
    "searchbutton.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e352f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1단계 검색어로 매장이름 데이터 만들기\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC \n",
    "\n",
    "#selenium에서 사용할 모듈 import\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "def search_bulit():\n",
    "    \"\"\"\n",
    "    구글맵 검색어 정의(지역 + 코드 + restaurants)\n",
    "    \"\"\"\n",
    "    df = pd.read_csv('bayareazipcode.csv', encoding='utf-8')\n",
    "    food_city = df['po_name']\n",
    "    food_code = df['zip']\n",
    "    food_state = df['state']\n",
    "    search_name = []\n",
    "    for i in range(len(food_city)):\n",
    "            name = food_city[i] + \" \" + str(food_code[i]) + \" Restaurants\" \n",
    "            search_name.append(name)\n",
    "    return search_name, food_code\n",
    "\n",
    "def wait_input(driver):\n",
    "    try:\n",
    "        element = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"tactile-searchbox-input\"))\n",
    "        ) #입력창이 뜰 때까지 대기\n",
    "    finally:\n",
    "        pass\n",
    "\n",
    "def input_funtion(n,driver,search_name):\n",
    "    print(search_name[n])\n",
    "    search_box = driver.find_element_by_id(\"searchboxinput\")\n",
    "    search_box.send_keys(search_name[n])\n",
    "    search_box.send_keys(Keys.ENTER) #검색창에 \"Los Banos 93635 Restaurants\" 입력\n",
    "\n",
    "def main_search(number,food_names,food_codes,error_search,food_code,driver,search_name):\n",
    "    #1차 100까지 2차 200\n",
    "    for n in range(0, number):\n",
    "        input_funtion(n,driver,search_name)\n",
    "        time.sleep(5)\n",
    "        while True:\n",
    "            try:\n",
    "                state = driver.find_element_by_id(\"ppdPk-Ej1Yeb-LgbsSe-tJiF1e\").get_attribute('disabled')\n",
    "            except:\n",
    "                error_search.append(search_name[n])\n",
    "                break\n",
    "                \n",
    "            if state != True:\n",
    "                try:\n",
    "                    #검색 결과로 나타나는 scroll-bar 포함한 div 잡고 스크롤 내리기\n",
    "                    scroll_div = driver.find_element_by_xpath('//*[@id=\"pane\"]/div/div[1]/div/div/div[2]/div[1]')\n",
    "                    driver.execute_script(\"arguments[0].scrollBy(0,2000)\", scroll_div)\n",
    "                    time.sleep(0.9)\n",
    "                    driver.execute_script(\"arguments[0].scrollBy(0,2000)\", scroll_div)\n",
    "                    time.sleep(0.9)\n",
    "                    driver.execute_script(\"arguments[0].scrollBy(0,2000)\", scroll_div)\n",
    "\n",
    "    #                 name = driver.find_elements_by_class_name(\"NrDZNb\")\n",
    "                    #한 칸 전체 데이터 가져오기\n",
    "                    elements = driver.find_elements_by_class_name('y7PRA')\n",
    "                    for i in range(20):\n",
    "                        try:\n",
    "                            food_codes.append(food_code[n])\n",
    "                            food_names.append(elements[i].text)\n",
    "                        except:\n",
    "                            break\n",
    "\n",
    "                    next_button = driver.find_element_by_id('ppdPk-Ej1Yeb-LgbsSe-tJiF1e')\n",
    "                    next_button.click()\n",
    "                    print(food_names)\n",
    "                    time.sleep(2.8)\n",
    "                except:\n",
    "                    break\n",
    "            else:\n",
    "                break\n",
    "                \n",
    "        try:\n",
    "            driver.find_element_by_class_name(\"sbcb_a\").click()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return food_names, food_codes\n",
    "\n",
    "def data_split(food_names,food_codes): # food_name 데이터를 필요한 정보만 저장하는 코드\n",
    "\n",
    "    food_name, food_name_code, rating, reviews, dollar, address = [], [], [], [], [], []\n",
    "\n",
    "    for i in range(len(food_names)):\n",
    "        food_name.append(food_names[i].split('\\n')[0])\n",
    "        food_name_code.append(food_codes[i])\n",
    "        if food_names[i].split('\\n')[1] == 'No reviews':\n",
    "            \n",
    "            rating.append(' ')\n",
    "            reviews.append(' ')\n",
    "            dollar.append(' ')\n",
    "        else:\n",
    "            try:\n",
    "                rating.append(food_names[i].split('\\n')[1].split(' · ')[0].split('(')[0])\n",
    "            except:\n",
    "                try:\n",
    "                    rating.append(food_names[i].split('\\n')[1].split('(')[0])\n",
    "                except:\n",
    "                    rating.append(' ')\n",
    "            try:\n",
    "                reviews.append(food_names[i].split('\\n')[1].split(' · ')[0].split('(')[1][:-1])\n",
    "            except: \n",
    "                try:\n",
    "                    reviews.append(food_names[i].split('\\n')[1].split('(')[1][:-1])\n",
    "                except:\n",
    "                    reviews.append(' ')\n",
    "            try:\n",
    "                dollar.append(food_names[i].split('\\n')[1].split(' · ')[1])\n",
    "            except:\n",
    "\n",
    "                dollar.append(' ')\n",
    "        try:\n",
    "            address.append(food_names[i].split('\\n')[2].split(' · ')[1])\n",
    "        except:\n",
    "            address.append(' ')\n",
    "    return food_names, food_name, food_name_code, rating, reviews, dollar, address\n",
    "\n",
    "def datafram_make(food_name,food_name_code,rating, reviews, dollar, address):\n",
    "    df = pd.DataFrame({\n",
    "                        'food_name' : food_name,\n",
    "                        'codezip' : food_name_code,\n",
    "                        'rating' : rating,\n",
    "                        'reviews' : reviews,\n",
    "                        'dollar' : dollar,\n",
    "                        'address' : address,\n",
    "                        })\n",
    "    df.to_csv('foodinfo_zeuskwon_200-끝.csv', encoding='utf-8-sig')\n",
    "    df.to_csv('H:\\\\내 드라이브\\\\foodinfo_zeuskwon_200-끝.csv', encoding='utf-8-sig')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    search_name,food_code = search_bulit() #매장이름, zipcode 데이터 불러오기\n",
    "\n",
    "    #언어변경\n",
    "    # 옵션 생성\n",
    "    options = webdriver.ChromeOptions()\n",
    "\n",
    "    # 옵션 추가\n",
    "    options.add_argument(\"--lang=en-GB\")\n",
    "    options.add_argument('disable-gpu') # GPU를 사용하지 않도록 설정\n",
    "    options.add_argument('headless')\n",
    "\n",
    "    # 브라우저 옵션을 적용하여 드라이버 생성\n",
    "    driver = webdriver.Chrome('chromedriver.exe', options=options) \n",
    "\n",
    "    link = 'https://www.google.com/maps'\n",
    "\n",
    "    driver.get(link)\n",
    "\n",
    "    wait_input(driver) #검색창 나올때까지 기다리기\n",
    "    \n",
    "    # driver , link = selenium_setting() # selenium사용을 위한 셋팅\n",
    "\n",
    "    number = len(search_name) # 검색할 데이터 수 \n",
    "\n",
    "    food_names,food_codes,error_search = [], [], [] # 음식점 이름 저장\n",
    "    food_names, food_codes = main_search(number,food_names,food_codes,error_search,food_code,driver,search_name)\n",
    "    food_names, food_name, food_name_code, rating, reviews, dollar, address = data_split(food_names,food_codes) # 이름저장한거 가져와서 데이터 가공하기 \n",
    "    datafram_make(food_name,food_name_code,rating, reviews, dollar, address)\n",
    "    driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow] *",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
